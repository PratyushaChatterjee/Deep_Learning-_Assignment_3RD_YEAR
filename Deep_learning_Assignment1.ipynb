{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPly1dkhRDFN8mY9tKCwQjZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratyushaChatterjee/Deep_Learning-_Assignment_3RD_YEAR/blob/main/Deep_learning_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Neuron:\n",
        "    # Define the input and output for training\n",
        "    input = np.array([[0, 1], [0, 0], [1, 1], [1, 0]])\n",
        "    output = np.array([0, 1, 1, 0])\n",
        "\n",
        "    # Initialize the weights and bias\n",
        "    weights = np.array([[0.4], [0.6]])\n",
        "    bias = 0.2\n",
        "\n",
        "    # Sigmoid activation function\n",
        "    def sigmoid_func(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    # Derivative of the sigmoid activation function\n",
        "    def sigmoid_derivative(self, z):\n",
        "        return self.sigmoid_func(z) * (1 - self.sigmoid_func(z))\n",
        "\n",
        "    # Prediction function\n",
        "    def predict(self, prediction):\n",
        "        # Calculate the weighted sum of inputs and add the bias\n",
        "        result = np.dot(prediction, self.weights) + self.bias\n",
        "        # Apply the activation function (sigmoid)\n",
        "        result = self.sigmoid_func(result)\n",
        "        return result\n",
        "\n",
        "# Create a neuron instance\n",
        "neuron = Neuron()\n",
        "\n",
        "# Make a prediction with the given input [1, 1]\n",
        "prediction = np.array([1, 1])\n",
        "output = neuron.predict(prediction)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJwzDj5bAWRo",
        "outputId": "09a2042b-e0e4-4b40-f31f-6833ba5f5f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.76852478]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh_func(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def der_tanh(y):\n",
        "    # Derivative of the tanh function\n",
        "    return 1 - np.square(y)\n",
        "\n",
        "# Assuming weight and bias are provided with appropriate values\n",
        "weight = np.array([0.4, 0.6])\n",
        "bias = 0.4\n",
        "# Input values for prediction\n",
        "prediction = np.array([0, 1])\n",
        "# Calculating the result\n",
        "result = np.dot(prediction, weight) + bias\n",
        "# print the final prediction probability\n",
        "final_result = tanh_func(result)\n",
        "\n",
        "print(final_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIUaNjduC-ho",
        "outputId": "58c2b1d2-4c25-4c35-9763-1850915465be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7615941559557649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def leaky_relu_func(x, leaky_slope=0.04):\n",
        "    return np.maximum(leaky_slope * x, x)\n",
        "\n",
        "def der_leaky_relu(y, leaky_slope=0.04):\n",
        "    # Derivative of the Leaky ReLU function\n",
        "    return 1.0 * (y > 0) + leaky_slope * (y <= 0)\n",
        "\n",
        "# Assuming weight and bias are provided with appropriate values\n",
        "weight = np.array([0.4, 0.6])\n",
        "bias = 0.4\n",
        "# Input values for prediction\n",
        "prediction = np.array([0, 1])\n",
        "# Calculating the result\n",
        "result = np.dot(prediction, weight) + bias\n",
        "# print the  final prediction probability\n",
        "final_result = leaky_relu_func(result)\n",
        "\n",
        "print(final_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQX7azBODQRJ",
        "outputId": "a2b9d0eb-4122-4502-efe0-6ac388e2b1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_func(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def der_relu(y):\n",
        "    # Derivative of the ReLU function\n",
        "    return 1 * (y > 0)\n",
        "\n",
        "# Assuming weight and bias are provided with appropriate values\n",
        "weight = np.array([0.4, 0.6])\n",
        "bias = 0.4\n",
        "# Input values for prediction\n",
        "prediction = np.array([0, 1])\n",
        "# Calculating the result\n",
        "result = np.dot(prediction, weight) + bias\n",
        "# print the final prediction probability\n",
        "final_result = relu_func(result)\n",
        "\n",
        "print(final_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lp7_K4NDqgk",
        "outputId": "50ef7b74-6bd4-4fd9-dbab-ed8f4ccf1d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    }
  ]
}